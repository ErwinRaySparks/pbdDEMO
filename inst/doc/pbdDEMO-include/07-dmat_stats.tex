\part{Distributed Matrix Methods}
\label{part:dmat}

%%% ----------------------------------------------------------------------
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Advanced Statistics Examples}

The \pkg{pbdDMAT} package contains many useful methods for doing computations with distributed matrices.  For comprehensive (but shallow) demonstrations of the distributed matrix methods available, see the \pkg{pbdDMAT} package's vignette and demos.

Here we showcase a few more advanced things that can be done by chaining together \proglang{R} and pbdR code seamlessly.

\section{Verification of Distributed System Solving}

\emph{Example:  Solve a system of equations and verify that the solution is correct.}

The demo command is
\begin{Command}
### At the shell prompt, run the demo with 4 processors by
### (Use Rscript.exe for windows system)
mpiexec -np 4 Rscript -e "demo(verify,'pbdDEMO',ask=F,echo=F)"
\end{Command}

The \pkg{pbdDEMO} contains a set of verification routines, designed to test for validity of the numerical methods at any scale.  Herein we will discuss the verification method for solving systems of linear equations, \code{verify.solve()}.

The process is simple.  The goal is to solve the equation (in matrix notation)
\begin{align*}
Ax=b
\end{align*}
for $n\times n$ matrix $A$ and $n\times 1$ matrix $b$.  However, here we start with $A$ and $x$ and use these to produce $b$.  We then forget we ever knew what $x$ was and solve the system.  Finally, we remember what $x$ really should be and compare that with our numerical solution.
  
More specifically, we take the matrix $A$ to be random normal generated data and the true solution $x$ to be a constant vector.  We then calculate
\begin{align*}
b := Ax
\end{align*}
and finally the system is solve for a now (pretend) unknown $x$, so that we can compare the numerically determined $x$ to the true constant $x$.  All processes are timed, and both success/failure and timing results are printed for the user at the completion of the routine. 

\begin{lstlisting}[language=rr,title=Verifying Distributed System Solving]
verify.solve <- function(nrows=1e3, mean=0, sd=1, const=1, bldim=8, tol=1e-7)
{
  # generating data
  time_data <- timer({
    x <- Hnorm(dim=c(nrows, nrows), bldim=bldim, mean=mean, sd=sd, ICTXT=0)
    truesol <- Hconst(dim=c(nrows, 1), bldim=bldim, const=const, ICTXT=0)
  })
  
  time_rhs <- timer({
    rhs <- x %*% truesol
  })

  # solving
  time_sol <- timer({
    sol <- solve(x, rhs)
  })
  
  # verifying
  time_verif <- timer({
    iseq <- all.equal(sol, truesol, tol=tol)
    iseq <- as.logical(allreduce(iseq, op='min'))
  })
  
  comm.cat("\nIs the factorization correct?  ", quiet=T)
  if (iseq)
    comm.cat("YES!\n", quiet=T)
  else {
    comm.cat("No...\n", quiet=T)
    s <- x-newx
    diffs <- c(min(s), mean(s), max(s))
    names(diffs) <- c("min", "mean", "max")
    comm.cat("\nPrinting min/mean/max differences between original and result from factoring and then multiplying...\n", quiet=T)
    comm.print(diffs, quiet=T)
  }
  
  comm.cat("\n\nRun times:\n", quiet=T)
  
  comm.print( 
         rbind(
            DataGeneration=time_data, 
            RHSgeneration=time_rhs,
            Solving=time_sol, 
            Verification=time_verif),
          quiet=T)
  
  tot <- time_data+time_rhs+time_sol+time_verif
  names(tot) <- c("", "", "")
  
  comm.print(rbind("Total         "=tot), quiet=T)
}
\end{lstlisting}








\section{Compression with Principal Components Analysis}

\emph{Example:  Take PCA and retain only a subset of the rotated data.}

The demo command is
\begin{Command}
### At the shell prompt, run the demo with 4 processors by
### (Use Rscript.exe for windows system)
mpiexec -np 4 Rscript -e "demo(pca,'pbdDEMO',ask=F,echo=F)"
\end{Command}

Suppose we wish to perform a principal components analysis and retain only some subset of the columns of the rotated data.  One of the ways this is often done is by using the singular values --- the standard deviations of the components --- as a measure of variation retained by a component.  However, the first step is to get the principal components data.  Luckily this is trivial.  If our data is stored in the distributed matrix object \code{dx}, then all we need to is issue the command:
\begin{lstlisting}[language=rr]
pca <- prcomp(x=dx, retx=TRUE, scale=TRUE)
\end{lstlisting}

Now that we have our PCA object (which has the same structure as that which comes from calling \code{prcomp()} on an ordinary \proglang{R} matrix), we need only decide how best to throw away what we do not want.  We might want to retain at least as many columns as would be needed to retain 90\% of the variation of the original data:

\begin{lstlisting}[language=rr]
prop_var <- cumsum(pca$sdev)/sum(pca$sdev)
i <- min(which(prop_var > 0.9))

new_dx <- pca$x[, 1:i]
\end{lstlisting}

Or we might want one fewer column than the number that would give us 90\%:

\begin{lstlisting}[language=rr]
prop_var <- cumsum(pca$sdev)/sum(pca$sdev)
i <- max(min(which(prop_var > 0.9)) - 1, 1)

new_dx <- pca$x[, 1:i]
\end{lstlisting}

